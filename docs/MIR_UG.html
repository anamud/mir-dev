<!DOCTYPE doctype HTML>
<html>
 <head>
  <meta charset="utf-8">
   <title>
    Made with Remarkable!
   </title>
   <link href="http://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.1/styles/github.min.css" rel="stylesheet">
    <script src="http://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.1/highlight.min.js">
    </script>
    <script>
     hljs.initHighlightingOnLoad();
    </script>
    <style type="text/css">
     body{font:16px Helvetica,Arial,sans-serif;line-height:1.4;color:#333;word-wrap:break-word;background-color:#fff;padding:10px 15px}strong{font-weight:700}h1{font-size:2em;margin:.67em 0;text-align:center}h2{font-size:1.75em}h3{font-size:1.5em}h4{font-size:1.25em}h1,h2,h3,h4,h5,h6{font-weight:700;position:relative;margin-top:15px;margin-bottom:15px;line-height:1.1}h1,h2{border-bottom:1px solid #eee}hr{height:0;margin:15px 0;overflow:hidden;background:0 0;border:0;border-bottom:1px solid #ddd}a{color:#4183C4}a.absent{color:#c00}ol,ul{padding-left:15px;margin-left:5px}ol{list-style-type:lower-roman}table{padding:0}table tr{border-top:1px solid #ccc;background-color:#fff;margin:0;padding:0}table tr:nth-child(2n){background-color:#aaa}table tr th{font-weight:700;border:1px solid #ccc;text-align:left;margin:0;padding:6px 13px}table tr td{border:1px solid #ccc;text-align:left;margin:0;padding:6px 13px}table tr td :first-child,table tr th :first-child{margin-top:0}table tr td:last-child,table tr th :last-child{margin-bottom:0}img{max-width:100%}code{padding:0 5px;background-color:#d3d3d3}blockquote{padding: 0 15px;border-left:4px solid #ccc}
    </style>
   </link>
  </meta>
 </head>
 <body>
  <h1>
   <mark>
    MIR User Guide
   </mark>
  </h1>
  <h1>
   Introduction
  </h1>
  <p>
   MIR is a task-based runtime system library written using C99 that provides detailed thread-based and task-based performance. MIR scales well for medium-grained task-based programs. MIR supports subset of the OpenMP 3.0 tasks interface and a low level native interface for writing task-based programs. MIR allows the user to experiment with memory distribution policies and different scheduling policies. Example: Locality-aware scheduling and data distribution on NUMA systems.
  </p>
  <h1>
   Intended Audience
  </h1>
  <p>
   MIR is intended to be used by advanced task-based programmers. Knowledge of compilation and runtime system role in task-based programming is required to use and appreciate MIR.
  </p>
  <h1>
   Installation
  </h1>
  <h2>
   Mandatory Requirements
  </h2>
  <ul>
   <li>
    Machine with x86 architecture.
   </li>
   <li>
    Linux kernel later than January 2012.
   </li>
   <li>
    GCC.
   </li>
   <li>
    Binutils.
   </li>
   <li>
    Scons build system.
   </li>
   <li>
    R  (for executing scripts)
   </li>
   <li>
    R packages
    <ul>
     <li>
      data.table (for data structure transformations)
     </li>
    </ul>
   </li>
  </ul>
  <h2>
   Optional Requirements
  </h2>
  <p>
   Enabling extended features such as profiling, locality-aware scheduling and data distribution requires:
  </p>
  <ul>
   <li>
    libnuma and numactl (for data distribution and locality-aware scheduling on NUMA systems)
   </li>
   <li>
    GCC with OpenMP support (for linking task-based OpenMP programs)
   </li>
   <li>
    PAPI (for reading hardware performance counters during profiling)
   </li>
   <li>
    Paraver (for visualizing thread execution traces)
   </li>
   <li>
    Python 2.X and 3.X (for executing various scripts)
   </li>
   <li>
    Intel Pin sources (for profiling instructions executed by tasks)
   </li>
   <li>
    R packages:
    <ul>
     <li>
      optparse (for parsing data)
     </li>
     <li>
      igraph (for task graph processing)
     </li>
     <li>
      RColorBrewer (for colors)
     </li>
     <li>
      gdata, plyr, dplyr, data.table (for data structure transformations)
     </li>
    </ul>
   </li>
   <li>
    Graphviz (for task graph plotting)
   </li>
  </ul>
  <h2>
   Source Structure
  </h2>
  <p>
   The source repository is structured intuitively. Files and directories have purpose-oriented names.
  </p>
  <pre><code>. : MIR_ROOT
|__docs : documentation
|__src : runtime system sources
    |__scheduling : scheduling policies
    |__arch : architecture specific sources 
|__scripts 
    |__helpers : helpful scripts, dirty hacks
    |__profiling : all things related to profiling
        |__task 
        |__thread
|__programs : test programs, benchmarks
    |__common : build scripts
    |__native : native interface programs
        |__fib
            |__helpers : testing scripts
    |__bots : BOTS port
    |__omp : OpenMP interface programs
        |__fib
</code></pre>
  <h2>
   Build
  </h2>
  <p>
   Follow below steps to build the basic runtime system library.
  </p>
  <ul>
   <li>
    Set MIR_ROOT environment variable.
   </li>
  </ul>
  <pre><code>$ export MIR_ROOT=&lt;MIR source repository path&gt;
</code></pre>
  <blockquote>
   <p>
    Tip:
    <br/>
    Add this to .bashrc to avoid repeated initialization.
   </p>
  </blockquote>
  <ul>
   <li>
    Build.
   </li>
  </ul>
  <pre><code>$ cd $MIR_ROOT/src
$ scons
</code></pre>
  <blockquote>
   <p>
    Expert Tip:
    <br/>
    Ensure MIR_ROOT/src/SConstruct matches your build intention.
   </p>
  </blockquote>
  <h3>
   Enabling data distribution and locality-aware scheduling on NUMA systems
  </h3>
  <ul>
   <li>
    Install libnuma and numactl.
   </li>
   <li>
    Create an empty file called HAVE_LIBNUMA.
   </li>
  </ul>
  <pre><code>$ touch $MIR_ROOT/src/HAVE_LIBNUMA
</code></pre>
  <ul>
   <li>
    Clean and rebuild MIR.
   </li>
  </ul>
  <pre><code>$ cd $MIR_ROOT/src
$ scons -c &amp;&amp; scons
</code></pre>
  <h2>
   Testing
  </h2>
  <p>
   Try different runtime system configurations and program inputs on Fibonacci in MIR_ROOT/programs/native/fib. Other programs in MIR_ROOT/programs can also be used for testing.
  </p>
  <pre><code>$ cd $MIR_ROOT/programs/native/fib
$ scons -c
$ scons
$ ./fib-verbose
$ ./fib-debug
$ ./fib-opt
</code></pre>
  <blockquote>
   <p>
    Note:
    <br/>
    A dedicated test suite will be added soon, so watch out for that!
   </p>
  </blockquote>
  <h1>
   Programming
  </h1>
  <h2>
   OpenMP 3.0 Tasks Interface
  </h2>
  <p>
   A restricted subset of OpenMP 3.0 tasks --- the
   <code>
    task
   </code>
   and
   <code>
    taskwait
   </code>
   constructs --- is supported. Although minimal, the subset is sufficient for writing most task-based programs.
  </p>
  <p>
   The
   <code>
    parallel
   </code>
   construct is deprecated. A team of threads is created when
   <code>
    mir_create
   </code>
   is called. The team is disbanded when
   <code>
    mir_destroy
   </code>
   is called.
  </p>
  <blockquote>
   <p>
    Note:
    <br/>
    OpenMP tasks are supported by intercepting GCC translated calls to GNU libgomp. OpenMP 3.0 task interface support is therefore restricted to programs compiled using GCC.
   </p>
  </blockquote>
  <h3>
   Tips for writing MIR-supported OpenMP programs
  </h3>
  <ul>
   <li>
    <p>
     Initialize and release the runtime system explicitly by calling
     <code>
      mir_create
     </code>
     and
     <code>
      mir_destroy
     </code>
     .
    </p>
   </li>
   <li>
    <p>
     Do not think in terms of threads.
    </p>
    <ul>
     <li>
      Do not use the
      <code>
       parallel
      </code>
      construct to share work.
     </li>
     <li>
      Do not use barriers to synchronize threads.
     </li>
    </ul>
   </li>
   <li>
    <p>
     Think solely in terms of tasks.
    </p>
    <ul>
     <li>
      Use the
      <code>
       task
      </code>
      construct to parallelize work.
     </li>
     <li>
      Use clauses
      <code>
       shared
      </code>
      ,
      <code>
       firstprivate
      </code>
      and
      <code>
       private
      </code>
      to indicate the data environment.
     </li>
     <li>
      Use
      <code>
       taskwait
      </code>
      to synchronize tasks.
     </li>
    </ul>
   </li>
   <li>
    <p>
     Use
     <code>
      mir_lock
     </code>
     instead of the
     <code>
      critical
     </code>
     construct or use OS locks such as
     <code>
      pthread_lock
     </code>
     .
    </p>
   </li>
   <li>
    <p>
     Use GCC atomic builtins for flushing and atomic operations.
    </p>
   </li>
   <li>
    <p>
     Study example programs in MIR_ROOT/programs/omp.
    </p>
   </li>
  </ul>
  <p>
   A simple set of steps for producing MIR-supported OpenMP programs is given below:
  </p>
  <ol>
   <li>
    <p>
     When parallel execution is required, create a
     <code>
      parallel
     </code>
     block with
     <code>
      default(none)
     </code>
     followed immediately by a
     <code>
      single
     </code>
     block. The
     <code>
      default(none)
     </code>
     clause avoids incorrect execution due to assumed sharing rules.
    </p>
   </li>
   <li>
    <p>
     Use the
     <code>
      task
     </code>
     construct within the
     <code>
      single
     </code>
     block to parallelize work.
    </p>
   </li>
   <li>
    <p>
     Synchronize tasks using the
     <code>
      taskwait
     </code>
     construct explicitly. Do not rely on implicit barriers and taskwaits.
    </p>
   </li>
   <li>
    <p>
     Parallelizing work inside a master task context is helpful while interpreting profiling results.
    </p>
   </li>
   <li>
    <p>
     Compile and link with the native OpenMP implementation (preferably libgomp) and check if the program runs correctly.
    </p>
   </li>
   <li>
    <p>
     Include
     <code>
      mir_public_int.h
     </code>
     . Call
     <code>
      mir_create
     </code>
     in the beginning of main and call
     <code>
      mir_destroy
     </code>
     at the end of main. Delete
     <code>
      parallel
     </code>
     and
     <code>
      single
     </code>
     blocks.
    </p>
   </li>
   <li>
    <p>
     Compile and link with the appropriate MIR library (opt/debug). The program is now ready.
    </p>
   </li>
  </ol>
  <p>
   The native interface example rewritten using above steps is shown below.
  </p>
  <pre><code>int main(int argc, char *argv[])
{
    // Initialize the runtime system
    mir_create();

#pragma omp task
{
    // Now parallelize the work involved
    // Work in this case: create as many tasks 
    // ... as there are threads
    int num_workers = mir_get_num_threads();
    for(int i=0; i&lt;num_workers; i++)
    {
        #pragma omp task firstprivate(i)
            foo(i);
    }

    // Wait for tasks to finish
    #pragma omp taskwait
}
// Wait for master task to finish
#pragma omp taskwait
    // Release runtime system resources
    mir_destroy();

    return 0;
}
</code></pre>
  <h2>
   Native Interface
  </h2>
  <p>
   Look at mir_public_int.h in MIR_ROOT/src for interface details and programs in MIR_ROOT/programs/native for interface usage examples. A simple program using the native interface is shown
   <br/>
   below.
  </p>
  <pre><code>#include "mir_public_int.h"
void foo(int id)
{
printf(stderr, "Hello from task %d\n", id);
}

// Task outline function argument
struct foo_wrapper_arg_t
{
int id;
};

// Task outline function
void foo_wrapper(void* arg)
{
    struct foo_wrapper_arg_t* farg = (struct foo_wrapper_arg_t*)(arg);
    foo(farg-&gt;id);
}

int main(int argc, char *argv[])
{
    // Initialize the runtime system
    mir_create();

    // Create as many tasks as there are threads
    int num_workers = mir_get_num_threads();
    for(int i=0; i&lt;num_workers; i++)
    {
        struct foo_wrapper_arg_t arg;
        arg.id = i;
        mir_task_create((mir_tfunc_t) foo_wrapper, 
                        &amp;arg, 
                        sizeof(struct foo_wrapper_arg_t), 
                        0, NULL, NULL);
    }

    // Wait for tasks to finish
    mir_task_wait();

    // Release runtime system resources
    mir_destroy();

    return 0;
}
</code></pre>
  <h2>
   Compiling and Linking
  </h2>
  <p>
   Add
   <code>
    -lmir-opt
   </code>
   to
   <code>
    LDFLAGS
   </code>
   . Enable MIR to intercept function calls
   <br/>
   correctly by adding
   <code>
    -fno-inline-functions
-fno-inline-functions-called-once -fno-optimize-sibling-calls
-fno-omit-frame-pointer -g
   </code>
   to
   <code>
    CFLAGS
   </code>
   and/or
   <code>
    CXXFLAGS
   </code>
   .
  </p>
  <h2>
   Runtime Configuration
  </h2>
  <p>
   MIR has several runtime configurable options which can be set using the environment variable
   <code>
    MIR_CONF
   </code>
   . Set the
   <code>
    -h
   </code>
   flag to see available configuration options.
  </p>
  <pre><code>$ cd $MIR_ROOT/test/fib
$ scons 
$ MIR_CONF="-h" ./fib-opt 3
MIR_INFO: Valid options in MIR_CONF environment variable ...
-h print this help message
-w=&lt;int&gt; number of workers
-s=&lt;str&gt; task scheduling policy. Choose among central, central-stack, ws, ws-de and numa.
-r enable worker recorder
-x=&lt;int&gt; task inlining limit based on num tasks per worker
-i collect worker statistics
-l=&lt;int&gt; worker stack size in MB
-q=&lt;int&gt; task queue capacity
-m=&lt;str&gt; memory allocation policy. Choose among coarse, fine and system.
-y=&lt;csv&gt; schedule policy specific parameters. Policy numa: data size in bytes below which task is dealt to worker's private queue.
-g collect task statistics
-p enable handshake with Outline Function Profiler [Note: Supported only for a single worker!]
</code></pre>
  <h3>
   Binding workers to cores
  </h3>
  <p>
   MIR creates and binds one worker thread per core (including hardware threads) by default. Binding is based on worker identifiers --- worker thread 0 is bound to core 0, worker thread 1 to core 1 and so on. The binding scheme can be changed to a specific mapping using the environment variable
   <code>
    MIR_WORKER_CORE_MAP
   </code>
   . Ensure
   <code>
    MIR_WORKER_EXPLICIT_BIND
   </code>
   is defined in
   <code>
    mir_defines.h
   </code>
   to enable explicit binding support. An example is shown below.
  </p>
  <pre><code>$ cd $MIR_ROOT/src
$ grep "EXPLICIT_BIND" mir_defines.h
#define MIR_WORKER_EXPLICIT_BIND
$ cat /proc/cpuinfo | grep -c Core
4
$ export MIR_WORKER_CORE_MAP="0,2,3,1"
$ cd $MIR_ROOT/programs/native/fib
$ scons 
$ ./fib-debug 10 3
MIR_DBG: Starting initialization ...
MIR_DBG: Architecture set to firenze
MIR_DBG: Memory allocation policy set to system
MIR_DBG: Task scheduling policy set to central-stack
MIR_DBG: Reading worker to core map ...
MIR_DBG: Binding worker 0 to core 3
MIR_DBG: Binding worker 3 to core 0
MIR_DBG: Binding worker 2 to core 2
MIR_DBG: Worker 2 is initialized!
MIR_DBG: Worker 3 is initialized!
MIR_DBG: Binding worker 1 to core 1
...
</code></pre>
  <h1>
   Profiling
  </h1>
  <p>
   MIR supports extensive thread-based and task-based profiling.
  </p>
  <h2>
   Thread-based Profiling
  </h2>
  <p>
   Thread states and events are the main performance indicators in thread-based profiling.
  </p>
  <p>
   Enable the
   <code>
    -i
   </code>
   flag to get basic load-balance information in a CSV file called
   <code>
    mir-worker-stats
   </code>
   .
  </p>
  <pre><code>$ MIR_CONF="-i" ./fib-opt
$ cat mir-worker-stats
</code></pre>
  <p>
   <mark>
    TODO:
   </mark>
   Explain file contents
  </p>
  <p>
   MIR contains a
   <code>
    recorder
   </code>
   which produces execution traces. Use the
   <code>
    -r
   </code>
   flag to enable the recorder and get detailed state and event traces in a set of
   <code>
    mir-recorder-trace-*.rec
   </code>
   files. Each file represents a worker thread. The files can be inspected individually or combined and visualized using Paraver.
  </p>
  <pre><code>$ MIR_CONF="-r" ./fib-opt
$ $MIR_ROOT/scripts/profiling/thread/rec2paraver.py \
mir-recorder-trace-config.rec 
$ wxparaver mir-recorder-trace.prv
</code></pre>
  <p>
   A set of
   <code>
    mir-recorder-state-time-*.rec
   </code>
   files are also created when
   <code>
    -r
   </code>
   is set. These files contain thread state duration information which can be accumulated for analysis without Paraver.
  </p>
  <pre><code>$ $MIR_ROOT/scripts/profiling/thread/get-states.sh \
mir-recorder-state-time
$ cat accumulated-state-file.info
</code></pre>
  <h3>
   Enabling hardware performance counters
  </h3>
  <p>
   MIR can read hardware performance counters through PAPI during thread events.
   <br/>
   * Install PAPI.
  </p>
  <ul>
   <li>
    Set the
    <code>
     PAPI_ROOT
    </code>
    environment variable
   </li>
  </ul>
  <pre><code>$ export PAPI_ROOT=&lt;PAPI install path&gt;
</code></pre>
  <ul>
   <li>
    Create a file called
    <code>
     HAVE_PAPI
    </code>
    in MIR_ROOT/src.
   </li>
  </ul>
  <pre><code>$ touch $MIR_ROOT/src/HAVE_PAPI
</code></pre>
  <ul>
   <li>
    Enable additional PAPI hardware performance counters by editing
    <code>
     MIR_ROOT/src/mir_recorder.c
    </code>
    .
   </li>
  </ul>
  <pre><code>$ grep -i "{PAPI_" $MIR_ROOT/src/mir_recorder.c
{"PAPI_TOT_INS", 0x0},
{"PAPI_TOT_CYC", 0x0},
/*{"PAPI_L2_DCM", 0x0},*/
/*{"PAPI_RES_STL", 0x0},*/
/*{"PAPI_L1_DCA", 0x0},*/
/*{"PAPI_L1_DCH", 0x0},*/
</code></pre>
  <ul>
   <li>
    Rebuild MIR.
   </li>
  </ul>
  <pre><code>$ scons -c &amp;&amp; scons
</code></pre>
  <p>
   Performance counter values will appear in the
   <code>
    mir-recorder-trace-*.rec
   </code>
   files produced by the recorder during thread-based profiling. The counter readings can either be viewed on Paraver or accumulated for analysis outside Paraver.
  </p>
  <pre><code>$ $MIR_ROOT/scripts/profiling/thread/get-events.sh mir-recorder-trace.prv
$ cat event-summary-*.txt
</code></pre>
  <h2>
   Task-based Profiling
  </h2>
  <p>
   Task are first-class citizens in task-based profiling.
  </p>
  <p>
   Enable the
   <code>
    -g
   </code>
   flag to collect task statistics in a CSV file called
   <code>
    mir-task-stats
   </code>
   . Inspect the file manually or plot and visualize the fork-join task graph.
  </p>
  <pre><code>$ MIR_CONF="-g" ./fib-opt
$ Rscript ${MIR_ROOT}/scripts/profiling/task/plot-task-graph.R -d mir-task-stats -c color
</code></pre>
  <p>
   <mark>
    TODO:
   </mark>
   Explain file contents.
  </p>
  <p>
   The
   <code>
    mir-task-stats
   </code>
   file can be further processed for additional information such as number of tasks and task lineage (UID for tasks).
  </p>
  <pre><code>$ Rscript ${MIR_ROOT}/scripts/profiling/task/process-task-stats.R -d mir-task-stats --lineage
$ cat mir-task-stats.info
num_tasks: 15
joins_at_summary: 1 2 2 1.875 2 2
$ head mir-task-stats.lineage
"task","parent","lineage"
1,0,"0-1"
2,1,"0-1-2"
3,1,"0-1-3"
...
$ head mir-task-stats.processed
...
</code></pre>
  <h3>
   Instruction-level task profiling
  </h3>
  <p>
   MIR provides a Pin-based instruction profiler that traces instructions executed by tasks.  Technically, the profiler traces instructions executed within outline functions of tasks in programs compiled using GCC. Follow below steps to build and use the profiler.
  </p>
  <ul>
   <li>
    Get Intel Pin sources and set environment variables.
   </li>
  </ul>
  <pre><code>$ export PIN_ROOT=&lt;Pin source path&gt;
$ export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$PIN_ROOT:$PIN_ROOT/intel64/runtime
</code></pre>
  <ul>
   <li>
    <p>
     Edit
     <code>
      PIN_ROOT/source/tools/Config/makefile.unix.config
     </code>
     and add
     <code>
      -fopenmp
     </code>
     to variables
     <code>
      TOOL_LDFLAGS_NOOPT
     </code>
     and
     <code>
      TOOL_CXXFLAGS_NOOPT
     </code>
    </p>
   </li>
   <li>
    <p>
     Build the profiler.
    </p>
   </li>
  </ul>
  <pre><code>$ cd $MIR_ROOT/scripts/profiling/task
$ make PIN_ROOT=$PIN_ROOT
</code></pre>
  <ul>
   <li>
    View profiler options using
    <code>
     -h
    </code>
    .
   </li>
  </ul>
  <pre><code>$ $PIN_ROOT/intel64/bin/pinbin -t $MIR_ROOT/scripts/profiling/task/obj-intel64/mir_of_profiler.so -h -- /usr/bin/echo
...
-c  [default ]
specify functions called (csv) from outline functions
-o  [default mir-ofp]
specify output file suffix
-s  [default ]
specify outline functions (csv)
...
</code></pre>
  <p>
   The profiler requires outline function names under the argument
   <code>
    -s
   </code>
   .  The argument
   <code>
    -c
   </code>
   accepts names of functions which are called within tasks.  The argument
   <code>
    --
   </code>
   separates profiled program invocation from profiler arguments.
  </p>
  <ul>
   <li>
    <p>
     The profiler requires handshaking with the runtime system. To enable handshaking, enable the
     <code>
      -p
     </code>
     flag in MIR_CONF.
    </p>
   </li>
   <li>
    <p>
     The profiler requires single-threaded execution of the profiled program.  Provide
     <code>
      -w=1
     </code>
     in MIR_CONF while profiling.
    </p>
   </li>
   <li>
    <p>
     Create a handy alias for invoking the profiler.
    </p>
   </li>
  </ul>
  <pre><code>$ alias mir-inst-prof="MIR_CONF='-w=1 -p' ${PIN_ROOT}/intel64/bin/pinbin -t ${MIR_ROOT}/scripts/profiling/task/obj-intel64/mir_of_profiler.so"

</code></pre>
  <ul>
   <li>
    <p>
     The profiler produces following outputs:
    </p>
    <ol>
     <li>
      <p>
       Per-task instructions in a CSV file called
       <code>
        mir-ofp-instructions
       </code>
       . Example contents of the file are shown below.
      </p>
      <p>
       <mark>
        TODO: Add file contents
       </mark>
      </p>
      <p>
       Each line shows instruction and code properties of a distinct task executed by the program. Properties are described below.
      </p>
      <ul>
       <li>
        <code>
         task
        </code>
        : Identifier of the task.
       </li>
       <li>
        <code>
         ins_count
        </code>
        : Total number of instructions executed by the task.
       </li>
       <li>
        <code>
         stack_read
        </code>
        : Number of read accesses to the stack while executing instructions.
       </li>
       <li>
        <code>
         stack_write
        </code>
        : Number of write accesses to the stack while executing instructions.
       </li>
       <li>
        <code>
         ccr
        </code>
        : Computation to Communication Ratio. Indicates number of instructions executed per read or write access to memory.
       </li>
       <li>
        <code>
         clr
        </code>
        : Computation to Load Ratio. Indicates number of instructions executed per read access to memory.
       </li>
       <li>
        <code>
         mem_read
        </code>
        : Number of read accesses to memory (excluding stack) while executing instructions.
       </li>
       <li>
        <code>
         mem_write
        </code>
        : Number of write accesses to memory (excluding stack) while executing instructions.
       </li>
       <li>
        <code>
         outl_func
        </code>
        : Name of the outline function of the task.
       </li>
      </ul>
     </li>
     <li>
      <p>
       Per-task events in a file called
       <code>
        mir-ofp-events
       </code>
       . Example contents of the file are shown below.
      </p>
      <pre><code>task,ins_count,[create],[wait]
14,446,[],[]
15,278,[],[]
10,60,[32,43,],[47,]
</code></pre>
      <p>
       Each line in the file shows events for a distinct task executed by the program. Event occurance is indicated in terms of instruction count. Events currently supported are:
      </p>
      <ul>
       <li>
        <code>
         create
        </code>
        : Indicates when child tasks were created. Example: [32,43] indicates the task 10 created its first child at instruction 32 and second child at 43. Tasks 14 and 15 did not create children tasks.
       </li>
       <li>
        <code>
         wait
        </code>
        : Indicates when child tasks were synchronized. Example: [47,] indicates the task 10 synchronized with all children created prior at instruction 47.
       </li>
      </ul>
     </li>
     <li>
      <p>
       Program memory map in a file called
       <code>
        mir-ofp-mem-map
       </code>
       . This is a copy of the memory map file of the program from the /proc filesystem.
      </p>
     </li>
    </ol>
   </li>
  </ul>
  <h2>
   Visualization
  </h2>
  <p>
   MIR has a nice graph plotter which can transform task-based profiling data into task graphs. The generated graph can be visualized on tools such as Graphviz, yEd and Cytoscape.
  </p>
  <ul>
   <li>
    Plot the fork-join task graph using task statistics from the runtime system.
   </li>
  </ul>
  <pre><code>$ Rscript ${MIR_ROOT}/scripts/profiling/task/plot-task-graph.R -d mir-task-stats -p color
</code></pre>
  <blockquote>
   <p>
    Tip:
    <br/>
    The graph plotter will plot in gray scale if
    <code>
     gray
    </code>
    is supplied instead of
    <code>
     color
    </code>
    as the palette (
    <code>
     -p
    </code>
    ) argument.
    <br/>
    Critical path enumeration usually takes time. To speed up, skip critical path enumeration and calculate only its length using option
    <code>
     --noCPE
    </code>
    .
   </p>
  </blockquote>
  <ul>
   <li>
    Huge graphs with 50000+ tasks take a long time to plot. Plot the task graph as a tree to save time.
   </li>
  </ul>
  <pre><code>$ Rscript ${MIR_ROOT}/scripts/profiling/task/plot-task-graph.R -t -d mir-task-stats -p color
</code></pre>
  <ul>
   <li>
    The graph plotter can annotate task graph elements with performance information. Merge the instruction-level information produced by the instruction profiler with the task statistics produced by the runtime system into a single CSV file. Plot task graph using combined performance information.
   </li>
  </ul>
  <pre><code>$ Rscript ${MIR_ROOT}/scripts/profiling/task/process-task-stats.R -d mir-task-stats
$ Rscript ${MIR_ROOT}/scripts/profiling/task/merge-task-performance.R -l mir-task-stats.processed -r mir-ofp-instructions -k "task" -o mir-task-perf
$ Rscript ${MIR_ROOT}/scripts/profiling/task/plot-task-graph.R -d mir-task-perf -p color
</code></pre>
  <h2>
   Case Study: Fibonacci
  </h2>
  <p>
   The Fibonacci program is found in MIR_ROOT/programs/native/fib. The program takes two arguments --- the number n and the depth cutoff for recursive task creation. Let us see how to profile the program for task-based performance information.
  </p>
  <ul>
   <li>
    Compile the program for profiling ---  remove aggressive optimizations and disable inlining so that outline functions representing tasks are visible to the Pin-based instruction profiler. Running scons in the program directory builds the profiler-friendly executable called
    <code>
     fib-prof
    </code>
    .
   </li>
  </ul>
  <pre><code>$ cd $MIR_ROOT/programs/native/fib
$ scons 
scons: Reading SConscript files ...
scons: done reading SConscript files.
scons: Building targets ...
scons: building associated VariantDir targets: debug-build opt-build prof-build verbose-build
...
gcc -o prof-build/fib.o -c -std=c99 -Wall -Werror -Wno-unused-function -Wno-unused-variable -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fopenmp -DLINUX -I/home/ananya/mir-dev/src -I/home/ananya/mir-dev/programs/common -O2 -DNDEBUG -fno-inline-functions -fno-inline-functions-called-once -fno-optimize-sibling-calls -fno-omit-frame-pointer -g fib.c
...
gcc -o fib-prof prof-build/fib.o -L/home/ananya/mir-dev/src -lpthread -lm -lmir-opt
</code></pre>
  <blockquote>
   <p>
    Tip:
    <br/>
    Look at the
    <code>
     SConstruct
    </code>
    file in MIR_ROOT/test/fib and build output to understand how the profiling-friendly build is done.
   </p>
  </blockquote>
  <ul>
   <li>
    Identify outline functions and functions called within tasks of the
    <code>
     fib-prof
    </code>
    program using the script
    <code>
     of_finder.py
    </code>
    . The script searches for known outline function name patterns within the object files of
    <code>
     fib-prof
    </code>
    . The script lists outline functions as
    <code>
     OUTLINE_FUNCTIONS
    </code>
    and all function symbols within the object files as
    <code>
     CALLED_FUNCTIONS
    </code>
    .
   </li>
  </ul>
  <pre><code>$ cd $MIR_ROOT/programs/native/fib
$ $MIR_ROOT/scripts/profiling/task/of_finder.py prof-build/*.o
Using "._omp_fn.|ol_" as outline function name pattern
Processing file: prof-build/fib.o
OUTLINE_FUNCTIONS=ol_fib_0,ol_fib_1,ol_fib_2
CALLED_FUNCTIONS=fib_seq,fib,get_usecs,main
</code></pre>
  <blockquote>
   <p>
    Expert Tip:
    <br/>
    Ensure that OUTLINE_FUNCTIONS listed are those generated by GCC. Inspect the abstract syntax tree (use compilation option
    <code>
     -fdumptreeoptimized
    </code>
    ) and source files.
   </p>
  </blockquote>
  <p>
   The functions in the
   <code>
    CALLED_FUNCTIONS
   </code>
   list should be treated as functions potentially called within task contexts.  Inspect program sources and exclude those which are not called within tasks.  By looking at Fibonacci program sources, we can exclude
   <code>
    main
   </code>
   and
   <code>
    get_usecs
   </code>
   from
   <code>
    CALLED_FUNCTIONS
   </code>
   .
  </p>
  <blockquote>
   <p>
    Tip: If in doubt or when sources are not available, use the entire
    <code>
     CALLED_FUNCTIONS
    </code>
    list.
   </p>
   <p>
    Expert Tip:
    <br/>
    Identifying functions called by tasks is necessary because the instruction count of these functions are added to the calling task's instruction count.
   </p>
  </blockquote>
  <ul>
   <li>
    Start the instruction profiler with appropriate arguments to profile
    <code>
     fib-prof
    </code>
    .
   </li>
  </ul>
  <pre><code>$ mir-inst-prof \
    -s ol_fib_0,ol_fib_1,ol_fib_2 \
    -c fib,fib_seq \
    -- ./fib-prof 10 4
</code></pre>
  <ul>
   <li>
    Inspect instruction profiler output.
   </li>
  </ul>
  <pre><code>$ head mir-ofp-instructions
"task","ins_count","stack_read","stack_write","mem_fp","ccr","clr","mem_read","mem_write","outl_func"
1,21887625,58,10,15,5,12,15,4,1,"ol_fib_2"
2,610035,60,10,15,5,12,15,4,1,"ol_fib_0"
3,3183115,60,10,15,5,12,15,4,1,"ol_fib_1"
...
$ head mir-ofp-events
task,ins_count,[create],[wait]
14,446,[],[]
15,278,[],[]
10,60,[32,43,],[47,]
...
</code></pre>
  <ul>
   <li>
    Collect task statistics.
   </li>
  </ul>
  <pre><code>MIR_CONF="-g" ./fib-prof 10 4
</code></pre>
  <blockquote>
   <p>
    Tip:
    <br/>
    Generate task statistics information simultaneously with other statistics to maintain consistency. Or you will have to merge using lineage as key.
   </p>
  </blockquote>
  <ul>
   <li>
    Summarize task statistics.
   </li>
  </ul>
  <pre><code>$ Rscript ${MIR_ROOT}/scripts/profiling/task/process-task-stats.R -d mir-task-stats
$ cat mir-task-stats.info
num_tasks: 15
joins_at_summary: 1 2 2 1.875 2 2
$ head mir-task-stats.processed
</code></pre>
  <ul>
   <li>
    Combine the instruction-level information produced by the instruction profiler with the task statistics produced by the runtime system into a single CSV file.
   </li>
  </ul>
  <pre><code>$ Rscript ${MIR_ROOT}/scripts/profiling/task/merge-task-performance.R -l mir-task-stats.processed -r mir-ofp-instructions -k "task" -o mir-task-perf
</code></pre>
  <ul>
   <li>
    Plot task graph using combined performance information and view on YEd.
   </li>
  </ul>
  <pre><code>$ Rscript ${MIR_ROOT}/scripts/profiling/task/plot-task-graph.R -d mir-task-perf -p color
$ yed task-graph.graphml
</code></pre>
 </body>
</html>