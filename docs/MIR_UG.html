<!DOCTYPE doctype HTML>
<html>
 <head>
  <meta charset="utf-8">
   <title>
    Made with Remarkable!
   </title>
   <link href="http://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.1/styles/github.min.css" rel="stylesheet">
    <script src="http://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.1/highlight.min.js">
    </script>
    <script>
     hljs.initHighlightingOnLoad();
    </script>
    <style type="text/css">
     body{font:16px Helvetica,Arial,sans-serif;line-height:1.4;color:#333;word-wrap:break-word;background-color:#fff;padding:10px 15px}strong{font-weight:700}h1{font-size:2em;margin:.67em 0;text-align:center}h2{font-size:1.75em}h3{font-size:1.5em}h4{font-size:1.25em}h1,h2,h3,h4,h5,h6{font-weight:700;position:relative;margin-top:15px;margin-bottom:15px;line-height:1.1}h1,h2{border-bottom:1px solid #eee}hr{height:0;margin:15px 0;overflow:hidden;background:0 0;border:0;border-bottom:1px solid #ddd}a{color:#4183C4}a.absent{color:#c00}ol,ul{padding-left:15px;margin-left:5px}ol{list-style-type:lower-roman}table{padding:0}table tr{border-top:1px solid #ccc;background-color:#fff;margin:0;padding:0}table tr:nth-child(2n){background-color:#aaa}table tr th{font-weight:700;border:1px solid #ccc;text-align:left;margin:0;padding:6px 13px}table tr td{border:1px solid #ccc;text-align:left;margin:0;padding:6px 13px}table tr td :first-child,table tr th :first-child{margin-top:0}table tr td:last-child,table tr th :last-child{margin-bottom:0}img{max-width:100%}code{padding:0 5px;background-color:#d3d3d3}blockquote{padding: 0 15px;border-left:4px solid #ccc}
    </style>
   </link>
  </meta>
 </head>
 <body>
  <h1>
   <mark>
    MIR User Guide
   </mark>
  </h1>
  <h1>
   Introduction
  </h1>
  <p>
   MIR is a task-based runtime system library written using C99. MIR scales well for medium-grained task-based programs. MIR provides a simple native interface for writing task-based programs. In addition, a subset of the OpenMP 3.0 tasks interface is supported. MIR is flexible --- the user can experiment with different scheduling policies. Example: Locality-aware scheduling and data distribution on NUMA systems. MIR supports extensive performance analysis and profiling features. Users can quickly solve performance problems using detailed thread-based and task-based performance information profiled by MIR.
  </p>
  <h1>
   Installation
  </h1>
  <h2>
   Mandatory Requirements
  </h2>
  <ul>
   <li>
    Machine with x86 architecture.
   </li>
   <li>
    Linux kernel later than January 2012.
   </li>
   <li>
    GCC.
   </li>
   <li>
    Binutils.
   </li>
   <li>
    Scons build system.
   </li>
  </ul>
  <h2>
   Optional Requirements
  </h2>
  <p>
   Enabling extended features such as profiling, locality-aware scheduling and data distribution requires:
  </p>
  <ul>
   <li>
    libnuma and numactl (for data distribution and locality-aware scheduling on NUMA systems)
   </li>
   <li>
    GCC with OpenMP support (for linking task-based OpenMP programs)
   </li>
   <li>
    PAPI (for reading hardware performance counters during profiling)
   </li>
   <li>
    Paraver (for visualizing thread execution traces)
   </li>
   <li>
    Python 2.X and 3.X (for executing profiling scripts)
   </li>
   <li>
    Intel Pin sources (for profiling instructions executed by tasks)
   </li>
   <li>
    R  (for executing profiling scripts)
   </li>
   <li>
    R packages:
    <ul>
     <li>
      igraph (for task graph processing)
     </li>
     <li>
      RColorBrewer (for colors)
     </li>
     <li>
      gdata, plyr (for data structure transformations)
     </li>
    </ul>
   </li>
   <li>
    Graphviz (for task graph plotting)
   </li>
  </ul>
  <h2>
   Source Structure
  </h2>
  <p>
   The source repository is structured intuitively. Files and directories have purpose-oriented names.
  </p>
  <pre><code>. : MIR_ROOT
|__docs : documentation
|__src : runtime system sources
    |__scheduling : scheduling policies
    |__arch : architecture specific sources 
|__scripts 
    |__donkeys : helper scripts, dirty hacks
    |__profiling : all things related to profiling
        |__task 
        |__thread
|__programs : test programs, benchmarks
    |__common : build scripts
    |__native : native interface programs
        |__fib
            |__donkeys : testing scripts
    |__bots : BOTS port
    |__omp : OpenMP interface programs
        |__fib
</code></pre>
  <h2>
   Build
  </h2>
  <p>
   Follow below steps to build the basic runtime system library.
  </p>
  <ul>
   <li>
    Set MIR_ROOT environment variable.
   </li>
  </ul>
  <pre><code>$ export MIR_ROOT=&lt;MIR source repository path&gt;
</code></pre>
  <blockquote>
   <p>
    Tip:
    <br/>
    Add this to .bashrc to avoid repeated initialization.
   </p>
  </blockquote>
  <ul>
   <li>
    Build.
   </li>
  </ul>
  <pre><code>$ cd $MIR_ROOT/src
$ scons
</code></pre>
  <blockquote>
   <p>
    Expert Tip:
    <br/>
    Ensure MIR_ROOT/src/SConstruct matches your build intention.
   </p>
  </blockquote>
  <h3>
   Enabling data distribution and locality-aware scheduling on NUMA systems
  </h3>
  <ul>
   <li>
    Install libnuma and numactl.
   </li>
   <li>
    Create an empty file called HAVE_LIBNUMA.
   </li>
  </ul>
  <pre><code>$ touch $MIR_ROOT/src/HAVE_LIBNUMA
</code></pre>
  <ul>
   <li>
    Clean and rebuild MIR.
   </li>
  </ul>
  <pre><code>$ cd $MIR_ROOT/src
$ scons -c &amp;&amp; scons
</code></pre>
  <h2>
   Testing
  </h2>
  <p>
   The Fibonacci program in MIR_ROOT/programs/native/fib is recommended for testing. Try different runtime system configurations
   <br/>
   and program inputs. Verify correctness and scalability. Other programs in MIR_ROOT/programs can also be used for testing.
  </p>
  <pre><code>$ cd $MIR_ROOT/programs/native/fib
$ scons -c
$ scons
$ ./fib-verbose
$ ./fib-debug
$ ./fib-opt
</code></pre>
  <blockquote>
   <p>
    Note:
    <br/>
    A dedicated test suite will be added soon, so watch out for that!
   </p>
  </blockquote>
  <h1>
   Programming
  </h1>
  <h2>
   Native Interface
  </h2>
  <p>
   The native interface for task-based programming is friendly, even to non-experts. Look at mir_public_int.h in MIR_ROOT/src for interface details and programs in MIR_ROOT/programs for interface usage examples. A simple program using the native interface is shown
   <br/>
   below.
  </p>
  <pre><code>#include "mir_public_int.h"
void foo(int id)
{
printf(stderr, "Hello from task %d\n", id);
}

// Task outline function argument
struct foo_wrapper_arg_t
{
int id;
};

// Task outline function
void foo_wrapper(void* arg)
{
    struct foo_wrapper_arg_t* farg = (struct foo_wrapper_arg_t*)(arg);
    foo(farg-&gt;id);
}

int main(int argc, char *argv[])
{
    // Initialize the runtime system
    mir_create();

    // Create as many tasks as there are threads
    int num_workers = mir_get_num_threads();
    for(int i=0; i&lt;num_workers; i++)
    {
        struct foo_wrapper_arg_t arg;
        arg.id = i;
        mir_task_create((mir_tfunc_t) foo_wrapper, 
                        &amp;arg, 
                        sizeof(struct foo_wrapper_arg_t), 
                        0, NULL, NULL);
    }

    // Wait for tasks to finish
    mir_task_wait();

    // Release runtime system resources
    mir_destroy();

    return 0;
}
</code></pre>
  <h2>
   OpenMP 3.0 Tasks Interface
  </h2>
  <p>
   A restricted subset of OpenMP 3.0 tasks --- the
   <code>
    task
   </code>
   and
   <code>
    taskwait
   </code>
   constructs --- is supported. Although minimal, the subset is sufficient for writing most task-based programs.
  </p>
  <p>
   The
   <code>
    parallel
   </code>
   construct is deprecated. A team of threads is created when
   <code>
    mir_create
   </code>
   is called. The team is disbanded when
   <code>
    mir_destroy
   </code>
   is called.
  </p>
  <blockquote>
   <p>
    Note:
    <br/>
    OpenMP tasks are supported by intercepting GCC translated calls to GNU libgomp. OpenMP 3.0 task interface support is therefore restricted to programs compiled using GCC.
   </p>
  </blockquote>
  <h3>
   Tips for writing MIR-supported OpenMP programs
  </h3>
  <ul>
   <li>
    <p>
     Initialize and release the runtime system explicitly by calling
     <code>
      mir_create
     </code>
     and
     <code>
      mir_destroy
     </code>
     .
    </p>
   </li>
   <li>
    <p>
     Do not think in terms of threads.
    </p>
    <ul>
     <li>
      Do not use the
      <code>
       parallel
      </code>
      construct to share work.
     </li>
     <li>
      Do not use barriers to synchronize threads.
     </li>
    </ul>
   </li>
   <li>
    <p>
     Think solely in terms of tasks.
    </p>
    <ul>
     <li>
      Use the
      <code>
       task
      </code>
      construct to parallelize work.
     </li>
     <li>
      Use clauses
      <code>
       shared
      </code>
      ,
      <code>
       firstprivate
      </code>
      and
      <code>
       private
      </code>
      to indicate the data environment.
     </li>
     <li>
      Use
      <code>
       taskwait
      </code>
      to synchronize tasks.
     </li>
    </ul>
   </li>
   <li>
    <p>
     Use
     <code>
      mir_lock
     </code>
     instead of the
     <code>
      critical
     </code>
     construct or use OS locks such as
     <code>
      pthread_lock
     </code>
     .
    </p>
   </li>
   <li>
    <p>
     Use GCC atomic builtins for flushing and atomic operations.
    </p>
   </li>
   <li>
    <p>
     Study example programs in MIR_ROOT/programs/omp.
    </p>
   </li>
  </ul>
  <p>
   A simple set of steps for producing MIR-supported OpenMP programs is given below:
  </p>
  <ol>
   <li>
    <p>
     When parallel execution is required, create a
     <code>
      parallel
     </code>
     block with
     <code>
      default(none)
     </code>
     followed immediately by a
     <code>
      single
     </code>
     block.
    </p>
   </li>
   <li>
    <p>
     Use the
     <code>
      task
     </code>
     construct within the
     <code>
      single
     </code>
     block to parallelize work.
    </p>
   </li>
   <li>
    <p>
     Synchronize tasks using the
     <code>
      taskwait
     </code>
     construct explicitly. Do not rely on implicit barriers and taskwaits.
    </p>
   </li>
   <li>
    <p>
     Parallelizing work inside a master task context is helpful while interpreting profiling results.
    </p>
   </li>
   <li>
    <p>
     Compile and link with the native OpenMP implementation (preferably libgomp) and check if the program runs correctly.
    </p>
   </li>
   <li>
    <p>
     Comment out the
     <code>
      parallel
     </code>
     and
     <code>
      single
     </code>
     blocks, initialize the MIR runtime system right in the beginning of the program by calling
     <code>
      mir_create
     </code>
     and release it at the end of the program by calling
     <code>
      mir_destroy
     </code>
     , include
     <code>
      mir_public_int.h
     </code>
     .
    </p>
   </li>
   <li>
    <p>
     Compile and link with the appropriate MIR library (opt/debug). The program is now ready.
    </p>
   </li>
  </ol>
  <p>
   The native interface example rewritten using above steps is shown below.
  </p>
  <pre><code>int main(int argc, char *argv[])
{
    // Initialize the runtime system
    mir_create();

//#pragma omp parallel default(none)
//{
//#pragma omp single
//{
// Master task context: helpful for interpreting profiling results.
#pragma omp task
{
    // Now parallelize the work involved
    // Work in this case: create as many tasks 
    // ... as there are threads
    int num_workers = mir_get_num_threads();
    for(int i=0; i&lt;num_workers; i++)
    {
        #pragma omp task firstprivate(i)
            foo(i);
    }

    // Wait for tasks to finish
    #pragma omp taskwait
}
// Wait for master task to finish
#pragma omp taskwait
//}
//}
    // Release runtime system resources
    mir_destroy();

    return 0;
}
</code></pre>
  <h2>
   Compiling and Linking
  </h2>
  <p>
   Look at
   <code>
    SConstruct
   </code>
   , the Scons build file accompanying each program to understand how to compile and link with the MIR library. Observing verbose build messages is also recommended.
  </p>
  <h2>
   Runtime Configuration
  </h2>
  <p>
   MIR has several runtime configurable options which can be set using the environment variable
   <code>
    MIR_CONF
   </code>
   . Set the
   <code>
    -h
   </code>
   flag to see available configuration options.
  </p>
  <pre><code>$ cd $MIR_ROOT/test/fib
$ scons 
$ MIR_CONF="-h" ./fib-opt 3
</code></pre>
  <h3>
   Binding workers to cores
  </h3>
  <p>
   MIR creates and binds one worker thread per core (including hardware threads) by default. Binding is based on worker identifiers --- worker thread 0 is bound to core 0, worker thread 1 to core 1 and so on. The binding scheme can be changed to a specific mapping using the environment variable
   <code>
    MIR_WORKER_CORE_MAP
   </code>
   . Ensure
   <code>
    MIR_WORKER_EXPLICIT_BIND
   </code>
   is defined in
   <code>
    mir_defines.h
   </code>
   to enable explicit binding support. An example is shown below.
  </p>
  <pre><code>$ cd $MIR_ROOT/src
$ grep "EXPLICIT_BIND" mir_defines.h
#define MIR_WORKER_EXPLICIT_BIND
$ cat /proc/cpuinfo | grep -c Core
4
$ export MIR_WORKER_CORE_MAP="0,2,3,1"
$ cd $MIR_ROOT/programs/native/fib
$ scons 
$ ./fib-debug 10 3
MIR_DBG: Starting initialization ...
MIR_DBG: Architecture set to firenze
MIR_DBG: Memory allocation policy set to system
MIR_DBG: Task scheduling policy set to central-stack
MIR_DBG: Reading worker to core map ...
MIR_DBG: Binding worker 0 to core 3
MIR_DBG: Binding worker 3 to core 0
MIR_DBG: Binding worker 2 to core 2
MIR_DBG: Worker 2 is initialized!
MIR_DBG: Worker 3 is initialized!
MIR_DBG: Binding worker 1 to core 1
...
</code></pre>
  <h1>
   Profiling
  </h1>
  <p>
   MIR supports extensive thread-based and task-based profiling.
  </p>
  <h2>
   Thread-based Profiling
  </h2>
  <p>
   Thread states and events are the main performance indicators in thread-based profiling.
  </p>
  <p>
   Enable the
   <code>
    -i
   </code>
   flag to get basic load-balance information in a CSV file called
   <code>
    mir-worker-stats
   </code>
   .
  </p>
  <pre><code>$ MIR_CONF="-i" ./fib-opt
$ cat mir-worker-stats

Enable the `-r` flag to get detailed per-thread state and event information in a set of `mir-recorder-prv-*.rec` files. Each file represents a worker thread. The files can be inspected individually or combined and visualized using Paraver.
</code></pre>
  <p>
   $ MIR_CONF="-r" ./fib-opt
   <br/>
   $ $MIR_ROOT/scripts/profiling/thread/mirtoparaver.py \
   <br/>
   mir-recorder-prv-config.rec
   <br/>
   $ wxparaver mir-recorder.prv
  </p>
  <pre><code>
A set of `mir-recorder-state-time-*.rec` files are also created when `-r` is enabled. The files contain thread state duration information which can be accumulated for analysis without Paraver.
</code></pre>
  <p>
   $ $MIR_ROOT/scripts/profiling/thread/get-state-stats.sh \
   <br/>
   mir-recorder-state-time
   <br/>
   $ cat state-file-acc.info
  </p>
  <pre><code>
### Enabling hardware performance counters

MIR can read hardware performance counters during thread events. This process is not fully automated and needs a little bit of hands-on work from the user.  

* Install PAPI.  

* Set the `PAPI_ROOT` environment variable 
</code></pre>
  <p>
   $ export PAPI_ROOT=
   <papi install="" path="">
   </papi>
  </p>
  <pre><code>
* Create a file called `HAVE_PAPI` in MIR_ROOT/src.  
</code></pre>
  <p>
   $ touch $MIR_ROOT/src/HAVE_PAPI
  </p>
  <pre><code>
* Enable the preprocessor definition `MIR_RECORDER_USE_HW_PERF_COUNTERS` in `MIR_ROOT/src/mir_defines.h`.  
</code></pre>
  <p>
   $grep -i HW_PERF $MIR_ROOT/src/mir_defines.h
  </p>
  <h1>
   define MIR_RECORDER_USE_HW_PERF_COUNTERS
  </h1>
  <pre><code>
* Enable PAPI hardware performance counters of interest in `MIR_ROOT/src/mir_recorder.c`.  
</code></pre>
  <p>
   $ grep -i "{\"PAPI_" $MIR_ROOT/src/mir_recorder.c
   <br/>
   {"PAPI_TOT_INS", 0x0},
   <br/>
   {"PAPI_TOT_CYC", 0x0},
   <br/>
   /
   <em>
    {"PAPI_L2_DCM", 0x0},
   </em>
   /
   <br/>
   /
   <em>
    {"PAPI_RES_STL", 0x0},
   </em>
   /
   <br/>
   /
   <em>
    {"PAPI_L1_DCA", 0x0},
   </em>
   /
   <br/>
   /
   <em>
    {"PAPI_L1_DCH", 0x0},
   </em>
   /
  </p>
  <pre><code>
 * Rebuild MIR.
</code></pre>
  <p>
   $ scons -c &amp;&amp; scons
  </p>
  <pre><code>
Performance counter readings will be now be added to `mir-recorder-prv-*.rec` files produced during thread-based profiling. The counter readings can either be viewed on Paraver or accumulated for analysis outside Paraver.
</code></pre>
  <p>
   $ $MIR_ROOT/scripts/profiling/thread/get-event-counts.sh mir-recorder-prv
   <br/>
   $ cat event-counts-*.txt
  </p>
  <pre><code>
## Task-based Profiling

Task are first-class citizens in task-based profiling.

Enable the `-g` flag to collect task statistics in a CSV file called `mir-task-stats`. Inspect the file manually or plot and visualize the fork-join task graph.
</code></pre>
  <p>
   $ MIR_CONF="-g" ./fib-opt
   <br/>
   $ Rscript ${MIR_ROOT}/scripts/profiling/task/fork-join-graph-plot.R mir-task-stats color
  </p>
  <pre><code>
### Instruction-level task profiling

MIR provides a Pin-based instruction profiler that traces instructions executed by tasks.  Technically, the profiler traces instructions executed within outline functions of tasks in programs compiled using GCC. Follow below steps to build and use the profiler. 

* Get Intel Pin sources and set environment variables.
</code></pre>
  <p>
   $ export PIN_ROOT=
   <pin path="" source="">
    <br/>
    $ export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$PIN_ROOT
   </pin>
  </p>
  <pre><code>
* Edit `PIN_ROOT/source/tools/Config/makefile.unix.config` and add `-fopenmp` to variables `TOOL_LDFLAGS_NOOPT` and `TOOL_CXXFLAGS_NOOPT`

* Build the profiler.
</code></pre>
  <p>
   $ cd $MIR_ROOT/scripts/profiling/task
   <br/>
   $ make PIN_ROOT=$PIN_ROOT
  </p>
  <pre><code>
* View profiler options using `-h`.
</code></pre>
  <p>
   $ $PIN_ROOT/intel64/bin/pinbin -t $MIR_ROOT/scripts/profiling/task/obj-intel64/mir_of_profiler.so -h -- /usr/bin/echo
   <br/>
   ...
   <br/>
   -c  [default ]
   <br/>
   specify functions called (csv) from outline functions
   <br/>
   -o  [default mir-ofp]
   <br/>
   specify output file suffix
   <br/>
   -s  [default ]
   <br/>
   specify outline functions (csv)
   <br/>
   ...
  </p>
  <pre><code>
The profiler requires outline function names under the argument `-s`.  The argument `-c` accepts names of functions which are called within tasks.  The argument `--` separates profiled program invocation from profiler arguments. 

* The profiler requires handshaking with the runtime system. To enable handshaking, enable the `-p` flag in MIR_CONF.

* The profiler requires single-threaded execution of the profiled program.  Provide `-w=1` in MIR_CONF while profiling. 

* Create a handy alias for invoking the profiler.
</code></pre>
  <p>
   $ alias mir-inst-prof="MIR_CONF='-w=1 -p' ${PIN_ROOT}/intel64/bin/pinbin -t ${MIR_ROOT}/scripts/profiling/task/obj-intel64/mir_of_profiler.so"
  </p>
  <pre><code>* The profiler produces following outputs: 
    1. Per-task instructions in a CSV file called `mir-ofp-instructions`. Example contents of the file are shown below. 

            "task","parent","joins_at","child_number","num_children","core_id","exec_cycles","ins_count","stack_read","stack_write","mem_fp","ccr","clr","mem_read","mem_write","name"
            1,0,0,0,2,0,21887625,58,10,15,5,12,15,4,1,"ol_fib_2"
            2,1,0,1,2,0,610035,60,10,15,5,12,15,4,1,"ol_fib_0"
            3,1,0,2,2,0,3183115,60,10,15,5,12,15,4,1,"ol_fib_1"

        Each line shows instruction and code properties of a distinct task executed by the program. Properties are described below.

        * `task`: Identifier of the task.
        * `parent`: Identifier of the parent task. 
        * `joins_at`: The order of synchronizing with the parent task context. 
        * `child_number`: Order of task creation by parent.
        * `num_children`: Indicates the number of child tasks created by the task.
        * `exec_cycles`: Number of cycles spent executing the task including child task creation and synchronization.
        * `core_id`: Identifier of the core that executed the task.
        * `ins_count`: Total number of instructions executed by the task. 
        * `stack_read`: Number of read accesses to the stack while executing instructions.
        * `stack_write`: Number of write accesses to the stack while executing instructions.
        * `ccr`: Computation to Communication Ratio. Indicates number of instructions executed per read or write access to memory.
        * `clr`: Computation to Load Ratio. Indicates number of instructions executed per read access to memory.
        * `mem_read`: Number of read accesses to memory (excluding stack) while executing instructions.
        * `mem_write`: Number of write accesses to memory (excluding stack) while executing instructions.
        * `name`: Name of the outline function of the task.

    2. Per-task events in a file called `mir-ofp-events`. Example contents of the file are shown below. 

            task,ins_count,[create],[wait]
            14,446,[],[]
            15,278,[],[]
            10,60,[32,43,],[47,]

        Each line in the file shows events for a distinct task executed by the program. Event occurance is indicated in terms of instruction count. Events currently supported are: 

        * `create`: Indicates when child tasks were created. Example: [32,43] indicates the task 10 created its first child at instruction 32 and second child at 43. Tasks 14 and 15 did not create children tasks.
        * `wait`: Indicates when child tasks were synchronized. Example: [47,] indicates the task 10 synchronized with all children created prior at instruction 47. 

    3. Program memory map in a file called `mir-ofp-mem-map`. This is a copy of the memory map file of the program from the /proc filesystem.

## Visualization

MIR contains several graph plotters which can transform task-based profiling data into task graphs. The graphs can be visualized on tools such as Graphviz, yEd and Cytoscape. 

* Plot the fork-join task graph using task statistics from the runtime system.
</code></pre>
  <p>
   $ Rscript ${MIR_ROOT}/scripts/profiling/task/fork-join-graph-plot.R mir-task-stats color
  </p>
  <pre><code>
&gt; Tip: 
&gt; The graph plotter will plot in gray scale if `gray` is supplied instead of `color` as argument. 

* Huge graphs with 50000+ tasks take a long time to plot. Plot the fork-join task graph as a tree to save time.
</code></pre>
  <p>
   $ Rscript ${MIR_ROOT}/scripts/profiling/task/tree-graph-plot.R mir-task-stats color
  </p>
  <pre><code>
* Use `${MIR_ROOT}/scripts/profiling/task/annotated-graph-plot.R` to plot task graphs with additional information embedded into graphical elements.

## Case Study: Fibonacci 

The Fibonacci program is found in MIR_ROOT/programs/native/fib. The program takes two arguments --- the number n and the depth cutoff for recursive task creation. Let us see how to profile the program for task-based performance information.

* Compile the program for profiling ---  remove aggressive optimizations and disable inlining so that outline functions representing tasks are visible to the Pin-based instruction profiler. Running scons in the program directory builds the profiler-friendly executable called `fib-prof`.
</code></pre>
  <p>
   $ cd $MIR_ROOT/programs/native/fib
   <br/>
   $ scons
   <br/>
   scons: Reading SConscript files ...
   <br/>
   scons: done reading SConscript files.
   <br/>
   scons: Building targets ...
   <br/>
   scons: building associated VariantDir targets: debug-build opt-build prof-build verbose-build
   <br/>
   ...
   <br/>
   gcc -o prof-build/fib.o -c -std=c99 -Wall -Werror -Wno-unused-function -Wno-unused-variable -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fopenmp -DLINUX -I/home/ananya/mir-dev/src -I/home/ananya/mir-dev/test/common -O2 -DNDEBUG -fno-inline-functions -fno-inline-functions-called-once -fno-optimize-sibling-calls -fno-omit-frame-pointer -g fib.c
   <br/>
   ...
   <br/>
   gcc -o fib-prof prof-build/fib.o -L/home/ananya/mir-dev/src -lpthread -lm -lmir-opt
  </p>
  <pre><code>
&gt; Tip: 
&gt; Look at the `SConstruct` file in MIR\_ROOT/test/fib and build output to understand how the profiling-friendly build is done.

* Identify outline functions and functions called within tasks of the `fib-prof` program using the script `of_finder.py`. The script searches for known outline function name patterns within the object files of `fib-prof`. The script lists outline functions as `OUTLINE_FUNCTIONS` and all function symbols within the object files as `CALLED_FUNCTIONS`.  
</code></pre>
  <p>
   $ cd $MIR_ROOT/programs/native/fib
   <br/>
   $ $MIR_ROOT/scripts/profiling/task/of_finder.py prof-build/*.o
   <br/>
   Using ".
   <em>
    omp_fn.|ol
   </em>
   " as outline function name pattern
   <br/>
   Processing file: prof-build/fib.o
   <br/>
   OUTLINE_FUNCTIONS=ol_fib_0,ol_fib_1,ol_fib_2
   <br/>
   CALLED_FUNCTIONS=fib_seq,fib,get_usecs,main
  </p>
  <pre><code>
&gt; Expert Tip: 
&gt; Ensure that OUTLINE_FUNCTIONS listed are those generated by GCC. Inspect the abstract syntax tree (use compilation option `-fdumptreeoptimized`) and source files.

The functions in the `CALLED_FUNCTIONS` list should be treated as functions potentially called within task contexts.  Inspect program sources and exclude those which are not called within tasks.  By looking at Fibonacci program sources, we can exclude `main` and `get_usecs` from `CALLED_FUNCTIONS`. 

&gt; Tip: If in doubt or when sources are not available, use the entire `CALLED_FUNCTIONS` list. 

&gt; Expert Tip: 
&gt; Identifying functions called by tasks is necessary because the instruction count of these functions are added to the calling task's instruction count. 

* Start the instruction profiler with appropriate arguments to profile `fib-prof`.  
</code></pre>
  <p>
   $ mir-inst-prof \
   <br/>
   -s ol_fib_0,ol_fib_1,ol_fib_2 \
   <br/>
   -c fib,fib_seq \
   <br/>
   -- ./fib-prof 10 4
  </p>
  <pre><code>
&gt; Tip: 
&gt; If you get a missing link-library error, add PIN_ROOT/intel64/runtime to LD_LIBRARY_PATH. 

* Inspect instruction profiler output. 

</code></pre>
  <p>
   $ head mir-ofp-instructions
   <br/>
   "task","parent","joins_at","child_number","num_children","core_id","exec_cycles","ins_count","stack_read","stack_write","mem_fp","ccr","clr","mem_read","mem_write","name"
   <br/>
   1,0,0,0,2,0,21887625,58,10,15,5,12,15,4,1,"ol_fib_2"
   <br/>
   2,1,0,1,2,0,610035,60,10,15,5,12,15,4,1,"ol_fib_0"
   <br/>
   3,1,0,2,2,0,3183115,60,10,15,5,12,15,4,1,"ol_fib_1"
   <br/>
   ...
   <br/>
   $ head mir-ofp-events
   <br/>
   task,ins_count,[create],[wait]
   <br/>
   14,446,[],[]
   <br/>
   15,278,[],[]
   <br/>
   10,60,[32,43,],[47,]
   <br/>
   ...
  </p>
  <pre><code>
* Collect task statistics.
</code></pre>
  <p>
   MIR_CONF="-g" ./fib-prof 10 4
  </p>
  <pre><code>&gt; Tip: 
&gt; Generate task statistics information simultaneously with other statistics to maintain consistency.

* Summarize task statistics.
</code></pre>
  <p>
   $ Rscript ${MIR_ROOT}/scripts/profiling/task/task-stats-summary.R mir-task-stats
   <br/>
   $ cat mir-task-stats.info
   <br/>
   num_tasks: 15
   <br/>
   joins_at_summary: 1 2 2 1.875 2 2
  </p>
  <pre><code>
* Combine the instruction-level information produced by the instruction profiler with the task statistics produced by the runtime system into a single CSV file.
</code></pre>
  <p>
   $ Rscript ${MIR_ROOT}/scripts/profiling/task/gather-task-performance.R mir-task-stats mir-ofp-instructions "mir-task-perf"
  </p>
  <pre><code>* Plot task graph using combined performance information and view on YEd.
</code></pre>
  <p>
   $ Rscript ${MIR_ROOT}/scripts/profiling/task/annotated-graph-plot.R mir-task-perf color
   <br/>
   $ yed mir-task-perf.graphml
   <br/>
   ```
  </p>
 </body>
</html>